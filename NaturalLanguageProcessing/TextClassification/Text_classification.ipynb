{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V__KYJdHK22"
   },
   "source": [
    "# Text Classification\n",
    "\n",
    "## \"*Words. I know words. I have the best words!*\"\n",
    "*- Noam Chomsky*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz_9qaHMHK24"
   },
   "source": [
    "# Overview\n",
    "\n",
    "To train an NLP model to classify text, we need:\n",
    "1. a way to preprocess text\n",
    "2. a label for each text\n",
    "3. a way to represent each text as vector input\n",
    "4. a model to learn  a function $f(input) = label$\n",
    "5. a way to evaluate how well the model works\n",
    "6. a way to predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUZsmiucHK25"
   },
   "source": [
    "# Checklist: how to classify my data\n",
    "\n",
    "1. label at ***least 2000*** instances in your data set\n",
    "2. preprocess the text of *all* instances in your data (labeled and unlabeled)\n",
    "3. read in the labeled instances and their labels\n",
    "4. use `TfidfVectorizer` to extract the features and transform them into feature vectors\n",
    "5. select the top $N$ features (where $N$ is smaller than the number of labeled instances)\n",
    "6. use 5-fold CV to find the best regularization parameter, top $N$ feature selection, and maybe feature generation and preprocessing steps\n",
    "7. create a classifier with the best settings\n",
    "\n",
    "Once you are satisfied with the results:\n",
    "\n",
    "8. read in the rest of the (unlabeled) instances\n",
    "9. use the `TfidfVectorizer` from 4. to transform the new data into vectors\n",
    "10. use the `SelectKBest` selector from 5. to get the top $N$ features\n",
    "11. use the classifier from 7. to predict the labels for the new data\n",
    "12. save the predicted labels or probabilities to your database or an Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXDp4JI3HK26"
   },
   "source": [
    "# The Data\n",
    "\n",
    "We'll use a subset of a Kaggle data set of wine reviews. For speed reasons, we will focus on descriptions of wines from France, Italy, Spain, and the US. The text data has already been preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Yr__zBRtH9Hx"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget http://www.dirkhovy.com/portfolio/papers/download/wine_reviews_classification.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KON9JFisHK27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>description_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>This wine is predominantly Cabernet Sauvignon ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Red Mountain</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>Red Blend</td>\n",
       "      <td>Col Solare</td>\n",
       "      <td>wine be predominantly remainder reserved aroma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>A blend of mainly Merlot and Cabernet Sauvigno...</td>\n",
       "      <td>Proprietary</td>\n",
       "      <td>91</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Bordeaux-style Red Blend</td>\n",
       "      <td>Alpha Omega</td>\n",
       "      <td>blend mainly small amount other traditional va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Expect exciting things from this Bordeaux-focu...</td>\n",
       "      <td>Gist Ranch Estate</td>\n",
       "      <td>93</td>\n",
       "      <td>55.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Cruz Mountains</td>\n",
       "      <td>Central Coast</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>expect exciting thing focus label offer scent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Dried herbs, grass and hay with some pear, app...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pinot Grigio</td>\n",
       "      <td>Stival</td>\n",
       "      <td>dry herb grass hay pear apple skin crush stone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>A clear winner at Morrison Lane, the Barbera i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Walla Walla Valley (WA)</td>\n",
       "      <td>Columbia Valley</td>\n",
       "      <td>Barbera</td>\n",
       "      <td>Morrison Lane</td>\n",
       "      <td>clear winner be enhance splash carry its beaut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                        description  \\\n",
       "0      US  This wine is predominantly Cabernet Sauvignon ...   \n",
       "1      US  A blend of mainly Merlot and Cabernet Sauvigno...   \n",
       "2      US  Expect exciting things from this Bordeaux-focu...   \n",
       "3   Italy  Dried herbs, grass and hay with some pear, app...   \n",
       "4      US  A clear winner at Morrison Lane, the Barbera i...   \n",
       "\n",
       "         designation  points  price    province                 region_1  \\\n",
       "0                NaN      93   75.0  Washington             Red Mountain   \n",
       "1        Proprietary      91   90.0  California              Napa Valley   \n",
       "2  Gist Ranch Estate      93   55.0  California     Santa Cruz Mountains   \n",
       "3                NaN      85    7.0      Veneto                   Veneto   \n",
       "4                NaN      90   24.0  Washington  Walla Walla Valley (WA)   \n",
       "\n",
       "          region_2                   variety         winery  \\\n",
       "0  Columbia Valley                 Red Blend     Col Solare   \n",
       "1             Napa  Bordeaux-style Red Blend    Alpha Omega   \n",
       "2    Central Coast        Cabernet Sauvignon      Lexington   \n",
       "3              NaN              Pinot Grigio         Stival   \n",
       "4  Columbia Valley                   Barbera  Morrison Lane   \n",
       "\n",
       "                                 description_cleaned  \n",
       "0  wine be predominantly remainder reserved aroma...  \n",
       "1  blend mainly small amount other traditional va...  \n",
       "2  expect exciting thing focus label offer scent ...  \n",
       "3  dry herb grass hay pear apple skin crush stone...  \n",
       "4  clear winner be enhance splash carry its beaut...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('wine_reviews_classification.xlsx')\n",
    "print(len(data))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PenA3PzHK29"
   },
   "source": [
    "Classifying new (**held-out**) data is called **prediction**. We reuse the weights we have learned before on a new data matrix to predict the new outcomes.\n",
    "\n",
    "Important: the new data needs to have the same number of features, and undergo the same preprocessing! The best way to ensure this is to make data splits just after the processing, before we do anything else.\n",
    "\n",
    "We will work with a random subset of 20000 instances, but you could use the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "IMpOG5d-HK29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "# determine the size of training, develpment and test set:\n",
    "N = len(data)\n",
    "train_size = int(N*0.5)\n",
    "dev_size = int(N*0.25)\n",
    "test_size = int(N*0.25)\n",
    "\n",
    "# split the data into training, develpment and test set:\n",
    "train = data[:train_size]\n",
    "dev = data[train_size: train_size+dev_size]\n",
    "test = data[train_size+dev_size:]\n",
    "print(len(train), len(dev), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_cHB3kUHK2-"
   },
   "source": [
    "Instead of manually splitting the data, you can also use `sklearn`'s built-in `StratifiedKFold` or `StratifiedShuffleSplit`, which ensures equal proportions of labels in all splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7oof6j2nHK2_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyAZljc6HK3A"
   },
   "source": [
    "# The Labels\n",
    "\n",
    "We'll predict the country of origin (Italy, US, France, or Spain) here, but we could potentially choose any other column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bQSwnRanHK3A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       US\n",
      "1       US\n",
      "2       US\n",
      "3    Italy\n",
      "4       US\n",
      "5       US\n",
      "6       US\n",
      "7       US\n",
      "8       US\n",
      "9       US\n",
      "Name: country, dtype: object\n"
     ]
    }
   ],
   "source": [
    "target = 'country'\n",
    "\n",
    "y_train = train[target]\n",
    "\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "--OSpAkhHK3B"
   },
   "outputs": [],
   "source": [
    "# select dev and test from the same label column\n",
    "y_dev = dev[target]\n",
    "y_test = test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp1FKH5GHK3B"
   },
   "source": [
    "You can get the classes (and their mapping to an intger) from the fitted classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29tt-4gYHK3C"
   },
   "source": [
    "Let's look at the label distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Gq24elFPHK3C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 0.5459, 'Italy': 0.1994, 'Spain': 0.0697, 'France': 0.185}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "{k: v/len(y_train) for k, v in Counter(y_train).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hFmTGb1mHK3D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Italy': 0.193, 'US': 0.5318, 'France': 0.2066, 'Spain': 0.0686}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v/len(y_dev) for k, v in Counter(y_dev).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eqP8vKN2HK3D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 0.5312, 'France': 0.1948, 'Italy': 0.2008, 'Spain': 0.0732}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v/len(y_test) for k, v in Counter(y_test).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efJ5DwdoHK3D"
   },
   "source": [
    "# Transforming the Input\n",
    "\n",
    "## Bags of words\n",
    "\n",
    "The easiest way is to represent features is as a counts of all words in the text. It takes two steps:\n",
    "1. collect the counts for each word\n",
    "2. transform the individual counts into one big matrix\n",
    "\n",
    "The result is a matrix $X$ with one row for each instance, and one column for each word in the vocabulary.\n",
    "\n",
    "![Bag of words procedure](bow.png)\n",
    "\n",
    "We can use the `TfidfVectorizer` object to get the frequency of each word, weighted by the number of documents it occurs in (that tempers the influence of freuqent, but uninformative words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2TfPunQHHK3D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4903)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), \n",
    "                             min_df=0.001, \n",
    "                             max_df=0.7, \n",
    "                             analyzer='word',\n",
    "                             sublinear_tf=True\n",
    "                            )\n",
    "\n",
    "X_train = vectorizer.fit_transform(train['description_cleaned'])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6VPMFC_PHK3F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 4903) (5000, 4903)\n"
     ]
    }
   ],
   "source": [
    "X_dev = vectorizer.transform(dev['description_cleaned'])\n",
    "X_test = vectorizer.transform(test['description_cleaned'])\n",
    "print(X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxVFp810HK3G"
   },
   "source": [
    "# Dummy Baseline\n",
    "\n",
    "So, is that performance good? Let's compare to a **baseline**, i.e., a null-hypothesis. The simplest one is that all instances belong to the most frequent class in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rmPNskfEHK3G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.00      0.00      0.00      1033\n",
      "       Italy       0.00      0.00      0.00       965\n",
      "       Spain       0.00      0.00      0.00       343\n",
      "          US       0.53      1.00      0.69      2659\n",
      "\n",
      "    accuracy                           0.53      5000\n",
      "   macro avg       0.13      0.25      0.17      5000\n",
      "weighted avg       0.28      0.53      0.37      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan-prada/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/juan-prada/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/juan-prada/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# find the most frequent class in the training data\n",
    "most_frequent = DummyClassifier(strategy='most_frequent')\n",
    "most_frequent.fit(X_train, y_train)\n",
    "\n",
    "# get the performance on the development set\n",
    "dumb_predictions = most_frequent.predict(X_dev)\n",
    "\n",
    "print(classification_report(y_dev, dumb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7Eqhp5jHK3H"
   },
   "source": [
    "Obviously, that's not very good. Which is actually good news, since it means we have a fair chance of doing better with a smarter classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwydhLuIHK3I"
   },
   "source": [
    "# A Classifier\n",
    "\n",
    "Let's use a simple Logistic Regression classifier. Technically, it is a Ridge classifier, because it is Logistic Regression with L2 regularization (see below), but we need not worry about that now.\n",
    "\n",
    "Let's fit a model, parallelizing it to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CYGtBfYCHK3I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.7 ms, sys: 61.4 ms, total: 106 ms\n",
      "Wall time: 1.98 s\n",
      "LogisticRegression(n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs')\n",
    "%time classifier.fit(X_train, y_train)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4SQu70MHK3I"
   },
   "source": [
    "To get the classes and their order/integer ID, you can use the `classes_` property of the fitted classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "91LwnNxVHK3J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['France', 'Italy', 'Spain', 'US'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBvZPONQHK3J"
   },
   "source": [
    "Let's get the performance of this classifier on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vz9XXdbvHK3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US' 'Italy' 'US' 'US' 'US' 'France' 'US' 'US' 'US' 'US']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.95      0.82      0.88      1033\n",
      "       Italy       0.93      0.90      0.92       965\n",
      "       Spain       0.90      0.61      0.73       343\n",
      "          US       0.88      0.98      0.93      2659\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.92      0.83      0.86      5000\n",
      "weighted avg       0.91      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_dev)\n",
    "print(predictions[:10])\n",
    "print(classification_report(y_dev,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4D41AHTHK3J"
   },
   "source": [
    "Instead, we can also predict the probabilities of belonging to each class. Here, we get  a distribution over classes, i.e., each column is the probability of one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UxoS9C2KHK3J"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>France</th>\n",
       "      <th>Italy</th>\n",
       "      <th>Spain</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067150</td>\n",
       "      <td>0.323007</td>\n",
       "      <td>0.037934</td>\n",
       "      <td>0.571908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.089626</td>\n",
       "      <td>0.790280</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.102752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032509</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>0.031237</td>\n",
       "      <td>0.918526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.290815</td>\n",
       "      <td>0.092499</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.602096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.981791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     France     Italy     Spain        US\n",
       "0  0.067150  0.323007  0.037934  0.571908\n",
       "1  0.089626  0.790280  0.017342  0.102752\n",
       "2  0.032509  0.017728  0.031237  0.918526\n",
       "3  0.290815  0.092499  0.014590  0.602096\n",
       "4  0.001192  0.004011  0.013006  0.981791"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = classifier.predict_proba(X_dev)\n",
    "\n",
    "prob_distro_df = pd.DataFrame(data=probabilities, columns=classifier.classes_)\n",
    "\n",
    "prob_distro_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2ZidHzYHK3J"
   },
   "source": [
    "The `predict()` function uses a threshold of $0.5$ to assign binary labels, or the argmax for multiple classes. If you want to emphasize precision more, you can base the label on a higher threshold. If you want to emphasize recall, you can base the label on a lower threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcOq5UIfHK3K"
   },
   "source": [
    "# Getting better\n",
    "\n",
    "If we do not like the results, there are several parameters we can experiment with:\n",
    "1. class balance\n",
    "2. regularization\n",
    "3. feature selection\n",
    "4. dimensionality reduction\n",
    "5. different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLasEApAHK3K"
   },
   "source": [
    "## 1. Class balance\n",
    "\n",
    "We can weigh each class inversely proportional to its frequency, i.e., assign higher weight to rarer classes, to improve performance on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8Zcpd2MJHK3K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 ms, sys: 753 µs, total: 19.7 ms\n",
      "Wall time: 1.04 s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.89      0.88      0.89      1033\n",
      "       Italy       0.88      0.92      0.90       965\n",
      "       Spain       0.71      0.89      0.79       343\n",
      "          US       0.95      0.90      0.93      2659\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.86      0.90      0.87      5000\n",
      "weighted avg       0.91      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_balanced = LogisticRegression(n_jobs=-1, \n",
    "                                         multi_class='auto', \n",
    "                                         solver='lbfgs', \n",
    "                                         class_weight='balanced' # added\n",
    "                                         \n",
    "                                        )\n",
    "%time classifier_balanced.fit(X_train, y_train)\n",
    "predictions_balanced = classifier_balanced.predict(X_dev)\n",
    "\n",
    "print(classification_report(y_dev, predictions_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3LdVuPOHK3L"
   },
   "source": [
    "## 2. Regularization strength\n",
    "Typically, performance is lower on unseen data, because our model **overfit** the training data: it expects the new data to look *exactly* the same as the training data. That is almost never true.\n",
    "\n",
    "In order to prevent the model from overfitting, we need to **regularize** it. Essentially, we make it harder to learn the training data.\n",
    "\n",
    "It makes sense to force the model to spread the weights more evenly over all features, rather than bet on a few feature, which mighht not be present in future data.\n",
    "\n",
    "We can do this by training the model with the `C` parameter of the L2 regularization. The default is `1`. Lower values mean stricter regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "cWCJ7DLIHK3L",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "New best performance: 0.9116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.90      0.88      0.89      1033\n",
      "       Italy       0.89      0.91      0.90       965\n",
      "       Spain       0.81      0.81      0.81       343\n",
      "          US       0.94      0.93      0.94      2659\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.88      0.89      0.88      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.90      0.88      0.89      1033\n",
      "       Italy       0.89      0.91      0.90       965\n",
      "       Spain       0.80      0.82      0.81       343\n",
      "          US       0.94      0.93      0.94      2659\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.88      0.89      0.88      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "10\n",
      "New best performance: 0.9122000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.90      0.89      0.89      1033\n",
      "       Italy       0.89      0.91      0.90       965\n",
      "       Spain       0.79      0.83      0.81       343\n",
      "          US       0.94      0.93      0.94      2659\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.88      0.89      0.89      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.90      0.89      0.89      1033\n",
      "       Italy       0.89      0.92      0.90       965\n",
      "       Spain       0.77      0.83      0.80       343\n",
      "          US       0.94      0.93      0.94      2659\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.88      0.89      0.88      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.90      0.89      0.89      1033\n",
      "       Italy       0.88      0.92      0.90       965\n",
      "       Spain       0.75      0.87      0.81       343\n",
      "          US       0.95      0.92      0.93      2659\n",
      "\n",
      "    accuracy                           0.91      5000\n",
      "   macro avg       0.87      0.90      0.88      5000\n",
      "weighted avg       0.91      0.91      0.91      5000\n",
      "\n",
      "\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.88      0.87      0.88      1033\n",
      "       Italy       0.87      0.91      0.89       965\n",
      "       Spain       0.68      0.90      0.77       343\n",
      "          US       0.94      0.90      0.92      2659\n",
      "\n",
      "    accuracy                           0.89      5000\n",
      "   macro avg       0.85      0.89      0.87      5000\n",
      "weighted avg       0.90      0.89      0.90      5000\n",
      "\n",
      "\n",
      "0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.86      0.84      0.85      1033\n",
      "       Italy       0.84      0.90      0.87       965\n",
      "       Spain       0.58      0.91      0.71       343\n",
      "          US       0.94      0.85      0.89      2659\n",
      "\n",
      "    accuracy                           0.86      5000\n",
      "   macro avg       0.80      0.88      0.83      5000\n",
      "weighted avg       0.88      0.86      0.87      5000\n",
      "\n",
      "\n",
      "0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.85      0.84      0.84      1033\n",
      "       Italy       0.83      0.90      0.86       965\n",
      "       Spain       0.54      0.91      0.68       343\n",
      "          US       0.94      0.84      0.88      2659\n",
      "\n",
      "    accuracy                           0.85      5000\n",
      "   macro avg       0.79      0.87      0.82      5000\n",
      "weighted avg       0.87      0.85      0.86      5000\n",
      "\n",
      "\n",
      "0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.80      0.85      0.82      1033\n",
      "       Italy       0.80      0.89      0.84       965\n",
      "       Spain       0.47      0.91      0.62       343\n",
      "          US       0.95      0.78      0.85      2659\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.76      0.86      0.79      5000\n",
      "weighted avg       0.86      0.82      0.83      5000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "best_c = None\n",
    "best_performance = 0.0\n",
    "\n",
    "for c in [50, 20, 10, 5, 2, 0.5, 0.1, 0.05, 0.01]:\n",
    "    print(c)\n",
    "    classifier_c = LogisticRegression(n_jobs=-1, \n",
    "                                      multi_class='auto', \n",
    "                                      solver='lbfgs',\n",
    "                                      class_weight='balanced',\n",
    "                                      C=c\n",
    "                                     )\n",
    "    \n",
    "    classifier_c.fit(X_train, y_train)\n",
    "    predictions_c = classifier_c.predict(X_dev)\n",
    "    score = f1_score(y_dev, predictions_c, average='micro')\n",
    "    if score > best_performance:\n",
    "        best_performance = score\n",
    "        best_c = c\n",
    "        print(\"New best performance: {}\".format(score))\n",
    "        \n",
    "    print(classification_report(y_dev, predictions_c))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDo8zAXPHK3L"
   },
   "source": [
    "Instead of a manual search, we can also use a grid search over all classifier parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zBuNRByrHK3L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(n_jobs=-1),\n",
       "             param_grid={'C': [20, 10, 5, 1, 0.01],\n",
       "                         'class_weight': ['balanced', None]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# setting up the classifier we want to optimize\n",
    "base_clf = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "# defining parameters to optimize\n",
    "param_grid = {'C': [20, 10, 5, 1, 0.01],\n",
    "              'class_weight': ['balanced', None]\n",
    "             }\n",
    "# run the optimization\n",
    "search = GridSearchCV(base_clf, # use the classifier defined above\n",
    "                      param_grid, # use the parameters defined above\n",
    "                      cv=5, # use 5-fold cross validation\n",
    "                      scoring='f1_micro') # use micro F1 to select best model\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TITyroaHK3N"
   },
   "source": [
    "Let's look at the winning combination of parameters: we access the `best_estimator_` property of the grid search object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "qsg3MXzLHK3N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': -1, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} 0.9091999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight='balanced', n_jobs=-1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best = search.best_estimator_\n",
    "print(clf_best.get_params(), search.best_score_)\n",
    "\n",
    "# fit this classifier on the entire training data, instead of CV\n",
    "clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuI65uPbHK3N"
   },
   "source": [
    "## 3. Feature selection\n",
    "\n",
    "Not all features are helpful. Let's select the top $k$ based on how well they predict they outcome of the training data.\n",
    "\n",
    "We use two libraries from `sklearn`, `SelectKBest` (the selection algorithm) and `chi2` (the selection criterion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "u3kI0AnOHK3N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9082000000000001 SelectKBest(k=4500, score_func=<function chi2 at 0x7f1ed60df280>)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# set up the sequence of steps\n",
    "pipe = Pipeline([\n",
    "    ('selector', 'passthrough'), # feature selection\n",
    "    ('classifier', clf_best) # the classifier\n",
    "])\n",
    "\n",
    "# specify selection range\n",
    "param_grid = [\n",
    "    {\n",
    "        'selector': [SelectKBest(chi2)],\n",
    "        'selector__k': [4500, 4000, 2000, 1000, 500]\n",
    "    },\n",
    "]\n",
    "\n",
    "# fit the model to different feature sets\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=5, \n",
    "                    scoring='f1_micro',\n",
    "                    n_jobs=-1,\n",
    "                   )\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_, grid.best_params_['selector'])\n",
    "\n",
    "# save the best selector\n",
    "selector = grid.best_params_['selector'].fit(X_train, y_train)\n",
    "\n",
    "# transform the data matrices of train, dev, and test to the new dimensionality\n",
    "X_train_sel = selector.transform(X_train)\n",
    "X_dev_sel = selector.transform(X_dev)\n",
    "X_test_sel = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5PTVE7HlHK3O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      France       0.89      0.88      0.89      1033\n",
      "       Italy       0.88      0.91      0.90       965\n",
      "       Spain       0.71      0.90      0.79       343\n",
      "          US       0.95      0.90      0.92      2659\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.86      0.90      0.87      5000\n",
      "weighted avg       0.91      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_sel = LogisticRegression(n_jobs=-1, multi_class='auto', solver='lbfgs', \n",
    "                                    class_weight='balanced')\n",
    "classifier_sel.fit(X_train_sel, y_train)\n",
    "\n",
    "predictions_sel = classifier_sel.predict(X_dev_sel)\n",
    "print(classification_report(y_dev, predictions_sel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0tCs-YPHK3O"
   },
   "source": [
    "## 4. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FcLog-v2HK3O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8824 TruncatedSVD(n_components=400)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# set up the sequence of steps\n",
    "pipe = Pipeline([\n",
    "    ('reduction', 'passthrough'),\n",
    "    ('classifier', clf_best)\n",
    "])\n",
    "\n",
    "# specify selection range\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduction': [TruncatedSVD()],\n",
    "        'reduction__n_components': [400, 300, 200, 100]\n",
    "    },\n",
    "]\n",
    "\n",
    "# fit the model to different feature sets\n",
    "grid = GridSearchCV(pipe, \n",
    "                    param_grid=param_grid, \n",
    "                    cv=5, \n",
    "                    scoring='f1_micro',\n",
    "                    n_jobs=-1,\n",
    "                   )\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_score_, grid.best_params_['reduction'])\n",
    "\n",
    "# save the best selector\n",
    "reductor = grid.best_params_['reduction'].fit(X_train, y_train)\n",
    "X_train_red = reductor.transform(X_train)\n",
    "X_dev_red = reductor.transform(X_dev)\n",
    "X_test_red = reductor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fICJDdLyHK3O"
   },
   "source": [
    "# Getting insights\n",
    "\n",
    "The fitted model has coefficients (weights, betas) for each word/feature in our vocabulary.\n",
    "\n",
    "To find out which features are most indicative for each class, we need some code to map back from the coefficient to the corresponding feature.\n",
    "\n",
    "If we reduced the number of features, we need to take that into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-cc_uENxHK3P"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>have enough</td>\n",
       "      <td>US</td>\n",
       "      <td>0.061937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>be its</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.061561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>sniff</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.061148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>plum sauce</td>\n",
       "      <td>France</td>\n",
       "      <td>0.061035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>pith</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.060195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>choppy</td>\n",
       "      <td>US</td>\n",
       "      <td>0.058745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>soapy</td>\n",
       "      <td>France</td>\n",
       "      <td>0.057313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>be particularly</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.054994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>background note</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.052861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>coffee ground</td>\n",
       "      <td>US</td>\n",
       "      <td>0.051947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>rich complex</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.049091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>that leave</td>\n",
       "      <td>US</td>\n",
       "      <td>0.049052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>be finish</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.048514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>exuberant</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0.044667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>flavor seem</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.043973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>fresh aftertaste</td>\n",
       "      <td>France</td>\n",
       "      <td>0.039362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>juicy red</td>\n",
       "      <td>France</td>\n",
       "      <td>0.037486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>chardonnay be</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.034642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>grape be</td>\n",
       "      <td>US</td>\n",
       "      <td>0.033837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>aroma prune</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0.024797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature   class  coefficient\n",
       "2227       have enough      US     0.061937\n",
       "465             be its   Spain     0.061561\n",
       "3889             sniff   Spain     0.061148\n",
       "3298        plum sauce  France     0.061035\n",
       "3267              pith   Italy     0.060195\n",
       "1024            choppy      US     0.058745\n",
       "3899             soapy  France     0.057313\n",
       "513    be particularly   Spain     0.054994\n",
       "277    background note   Italy     0.052861\n",
       "1101     coffee ground      US     0.051947\n",
       "3541      rich complex   Italy     0.049091\n",
       "4343        that leave      US     0.049052\n",
       "422          be finish   Italy     0.048514\n",
       "1634         exuberant   Italy     0.044667\n",
       "1838       flavor seem   Spain     0.043973\n",
       "1915  fresh aftertaste  France     0.039362\n",
       "2463         juicy red  France     0.037486\n",
       "938      chardonnay be   Spain     0.034642\n",
       "2140          grape be      US     0.033837\n",
       "216        aroma prune   Spain     0.024797"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the names of the features\n",
    "features = vectorizer.get_feature_names()\n",
    "num_feats = len(features)\n",
    "reduced_size = classifier_sel.coef_.shape[1]\n",
    "\n",
    "# get the indices of the selection\n",
    "top_scores = selector.scores_.argsort()[-num_feats:]\n",
    "\n",
    "# sort feature names\n",
    "best_indicator_terms = [features[i] for i in sorted(top_scores)] \n",
    "\n",
    "# get class with highest weight for each feature\n",
    "top_class = [classifier_sel.classes_[c] for c in classifier_sel.coef_.argmax(axis=0)]\n",
    "\n",
    "# make DataFrame\n",
    "top_indicator_scores = pd.DataFrame(data={'feature': best_indicator_terms[:reduced_size], \n",
    "                                          'class': top_class[:reduced_size],\n",
    "                                          'coefficient': classifier_sel.coef_.max(axis=0)})\n",
    "\n",
    "# sort in descending order\n",
    "top_indicator_scores.sort_values('coefficient', ascending=False, inplace=True)\n",
    "top_indicator_scores.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FUhaPKCHK3Q"
   },
   "source": [
    "# Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6_k61NCBHK3Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def bootstrap_sample(system1, system2, gold, samples=1000, score=f1_score, average='micro'):\n",
    "    \"\"\"\n",
    "    compute the proportion of times the performance difference of the \n",
    "    two systems on a subsample is significantly different from the \n",
    "    performance on the entire sample\n",
    "    \"\"\"\n",
    "    N = len(gold) # number of instances\n",
    "    \n",
    "    # make sure the two systems have the same number of samples\n",
    "    assert len(system1) == N and len(system2) == N, 'samples have different lengths'\n",
    "\n",
    "    # compute performance score on entire sample\n",
    "    base_score1 = score(gold, system1, average=average)\n",
    "    base_score2 = score(gold, system2, average=average)\n",
    "    print(\"Base difference: {} vs. {}\".format(base_score1, base_score2))\n",
    "\n",
    "    # switch systems if system2 is better\n",
    "    if base_score2 > base_score1:\n",
    "        system1, system2 = system2, system1\n",
    "        base_score1, base_score2 = base_score2, base_score1\n",
    "    \n",
    "    # compute the difference\n",
    "    basedelta = base_score1 - base_score2\n",
    "    assert basedelta > 0, 'Wrong system first, system1 needs to be better!'\n",
    "\n",
    "    system1 = np.array(system1)\n",
    "    system2 = np.array(system2)\n",
    "    gold = np.array(gold)\n",
    "\n",
    "    p = 0\n",
    "    deltas = []\n",
    "    for i in range(samples):\n",
    "        # select a subsample, with replacement\n",
    "        sample = np.random.choice(N, size=N, replace=True)\n",
    "\n",
    "        # collect data corresponding to subsample\n",
    "        sample1 = system1[sample]\n",
    "        sample2 = system2[sample]\n",
    "        gold_sample = gold[sample]\n",
    "\n",
    "        # compute scores on subsample\n",
    "        sample_score1 = score(gold_sample, sample1, average=average)\n",
    "        sample_score2 = score(gold_sample, sample2, average=average)\n",
    "        sample_delta = sample_score1 - sample_score2\n",
    "\n",
    "        # check whether the observed sample difference is at least \n",
    "        # twice as large as the base difference\n",
    "        if sample_delta > 2*basedelta:\n",
    "            p += 1\n",
    "        deltas.append(sample_delta)\n",
    "                \n",
    "    return p/samples, deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RFNrw9Y5HK3R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base difference: 0.9048 vs. 0.5318\n",
      "0.0 True\n"
     ]
    }
   ],
   "source": [
    "p_value, deltas = bootstrap_sample(predictions, dumb_predictions, y_dev)\n",
    "print(p_value, p_value < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Xrx4FaOyHK3R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.Series(deltas).plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KU-uo41FHK3R"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
